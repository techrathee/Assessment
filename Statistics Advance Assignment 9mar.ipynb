{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754f8bc2-2b60-4783-aed3-08d0c5c9485a",
   "metadata": {},
   "source": [
    "# Statistics Advance-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff7b33-9c57-4a59-a640-7a0d4e5ba3c3",
   "metadata": {},
   "source": [
    "## 09mar 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21210945-d149-47be-b3d0-9ad84b7b7f81",
   "metadata": {},
   "source": [
    "### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155ab5f-8e21-4647-b356-d7ad7499be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical functions used in probability theory and statistics to describe the probabilities associated\n",
    "with different outcomes of a discrete random variable (for PMF) or a continuous random variable (for PDF).\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "    \n",
    "    The Probability Mass Function (PMF) is used for discrete random variables, which take on specific individual values with certain probabilities. It gives the probability of each\n",
    "    possible value of the random variable. The sum of all probabilities in the PMF must be equal to 1.\n",
    "    \n",
    "    Mathematically, the PMF of a discrete random variable X is defined as:\n",
    "        \n",
    "        PMF(X = x) = P(X = x)\n",
    "        \n",
    "        where x represents a specific value that X can take, and PMF(X = x) gives the probability of X taking that specific value.\n",
    "        \n",
    "        Example of PMF:\n",
    "            \n",
    "            Let's consider a fair six-sided die. The random variable X represents the outcome when the die is rolled. Since the die is fair, each face has an equal chance of showing up,\n",
    "            and the PMF is as follows:\n",
    "                \n",
    "                PMF(X = 1) = 1/6\n",
    "                PMF(X = 2) = 1/6\n",
    "                PMF(X = 3) = 1/6\n",
    "                PMF(X = 4) = 1/6\n",
    "                PMF(X = 5) = 1/6\n",
    "                PMF(X = 6) = 1/6\n",
    "                \n",
    "Probability Density Function (PDF):\n",
    "    \n",
    "    The Probability Density Function (PDF) is used for continuous random variables, which can take on any value within a certain range, typically an interval on the real number line.\n",
    "    Unlike PMF, the PDF does not give the probability at a specific point but instead gives the probability density at a given point. To find the probability of a continuous random\n",
    "    variable falling within a specific interval, you need to integrate the PDF over that interval.\n",
    "    \n",
    "    Mathematically, the PDF of a continuous random variable X is represented by f(x), and for any value x within the range of X:\n",
    "        \n",
    "        P(a ≤ X ≤ b) = ∫(a to b) f(x) dx\n",
    "        \n",
    "        where P(a ≤ X ≤ b) represents the probability of X lying between a and b.\n",
    "        \n",
    "        Example of PDF:\n",
    "            Consider a uniform distribution between 0 and 1. The PDF, denoted by f(x), is constant within this interval and equal to 1. Outside this range, the PDF is 0.\n",
    "            \n",
    "            For this uniform distribution, the PDF is given as:\n",
    "                f(x) = 1, if 0 ≤ x ≤ 1\n",
    "                f(x) = 0, otherwise\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb0e8d-8e94-4c0d-9646-7e04522c8bfa",
   "metadata": {},
   "source": [
    "### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c22481-ab93-4ccc-a8bc-182a7f487842",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "\n",
    "The Cumulative Distribution Function (CDF) is a function that describes the probability that a random variable takes on a value less than or equal to a given value. It provides a\n",
    "cumulative measure of the probabilities associated with the outcomes of a random variable.\n",
    "\n",
    "Mathematically, for a random variable X, the CDF is defined as:\n",
    "    \n",
    "    CDF(x) = P(X ≤ x)\n",
    "\n",
    "where x represents a specific value, and CDF(x) gives the probability of X being less than or equal to x.\n",
    "\n",
    "The CDF provides a range of information about the distribution of a random variable, such as the probability of observing values below or equal to a particular value, the probability \n",
    "of values falling within certain intervals, and even the probability of observing values above a certain threshold.\n",
    "\n",
    "Example of CDF:\n",
    "    Consider a fair six-sided die. The random variable X represents the outcome when the die is rolled. The CDF for this discrete random variable is as follows:\n",
    "        \n",
    "        CDF(X = 1) = P(X ≤ 1) = 1/6\n",
    "        CDF(X = 2) = P(X ≤ 2) = 2/6\n",
    "        CDF(X = 3) = P(X ≤ 3) = 3/6\n",
    "        CDF(X = 4) = P(X ≤ 4) = 4/6\n",
    "        CDF(X = 5) = P(X ≤ 5) = 5/6\n",
    "        CDF(X = 6) = P(X ≤ 6) = 6/6 = 1\n",
    "        \n",
    "For example, CDF(X = 3) represents the probability of getting a value less than or equal to 3 when rolling the die. In this case, it would be 3/6 or 0.5.\n",
    "\n",
    "Why CDF is used:\n",
    "    The CDF is used for several reasons:\n",
    "        \n",
    "        1. Probability calculations: The CDF allows us to calculate the probability of a random variable falling within a certain range or being less than or equal to a specific value. \n",
    "        It provides a convenient way to obtain probabilities associated with various events.\n",
    "        \n",
    "        2. Distribution characterization: The CDF provides a complete description of the distribution of a random variable. It allows us to determine important statistical properties,\n",
    "        such as the median (50th percentile), quartiles, percentiles, and other quantiles of the distribution.\n",
    "        \n",
    "        3. Random variable comparison: The CDF enables the comparison of different random variables. By comparing their CDFs, we can assess how their probabilities differ and identify\n",
    "        relationships or similarities between distributions.\n",
    "        \n",
    "        4. Hypothesis testing: In statistical hypothesis testing, the CDF is used to determine critical values and calculate p-values, which help assess the strength of evidence against\n",
    "        a particular hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28396780-bc04-4cb0-af6d-0f51458ce2b3",
   "metadata": {},
   "source": [
    "### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71912b5d-ce3a-465b-b705-444226cee1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, is a commonly used probability distribution in statistics. It is widely applicable in various fields to\n",
    "model real-world phenomena. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "    \n",
    "    1. Height of Individuals:\n",
    "        The heights of adult individuals tend to follow a roughly normal distribution. The mean and standard deviation of the normal distribution can be used to describe the average\n",
    "        height and the variability of heights in a population.\n",
    "        \n",
    "    2. Test Scores:\n",
    "        Test scores often exhibit a normal distribution when a large number of people take the test. The mean and standard deviation of the normal distribution can be used to describe \n",
    "        the average performance and the spread of scores.\n",
    "        \n",
    "    3. Measurement Errors:\n",
    "        Measurement errors in scientific experiments often follow a normal distribution. By modeling the errors as normally distributed, statistical techniques can be applied to estimate\n",
    "        the true values and assess the uncertainty.\n",
    "        \n",
    "    4. IQ Scores:\n",
    "        IQ (Intelligence Quotient) scores are often assumed to follow a normal distribution. The mean and standard deviation of the normal distribution can be used to describe the\n",
    "        average intelligence level and the variation in IQ scores.\n",
    "        \n",
    "    5. Financial Returns:\n",
    "        In finance, the daily or monthly returns of stock prices or other financial assets are often assumed to be normally distributed. This assumption allows for the application of\n",
    "        various mathematical models and risk analysis techniques.\n",
    "        \n",
    "The parameters of the normal distribution—mean (μ) and standard deviation (σ)—are essential in defining the shape of the distribution:\n",
    "    \n",
    "    1. Mean (μ):\n",
    "        The mean determines the central tendency or the average value of the distribution. It represents the location of the peak of the bell curve. Shifting the mean to the left or\n",
    "        right moves the entire distribution along the x-axis.\n",
    "        \n",
    "    2. Standard Deviation (σ):\n",
    "        The standard deviation quantifies the dispersion or spread of the distribution. A smaller standard deviation results in a narrower, more concentrated bell curve, while a larger \n",
    "        standard deviation leads to a wider, more spread-out curve.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c8eb1-d3b3-403a-8758-a8c22797cd46",
   "metadata": {},
   "source": [
    "### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1579c799-2e5e-4d32-b4e3-125e32bea6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, is of great importance in statistics and probability theory. Its significance stems from several key \n",
    "reasons:\n",
    "    \n",
    "    1. Widely Applicable: \n",
    "        The normal distribution is widely applicable as a model for many natural phenomena and real-world variables. It arises naturally in situations where multiple independent factors\n",
    "        contribute to the observed outcome, such as measurement errors, physical dimensions, and biological traits.\n",
    "        \n",
    "    2. Central Limit Theorem:\n",
    "        The normal distribution plays a fundamental role in the Central Limit Theorem (CLT). According to the CLT, when independent random variables are added together, their sum tends \n",
    "        to follow a normal distribution, regardless of the original distributions. This property allows the normal distribution to serve as an approximation for many complex phenomena.\n",
    "        \n",
    "    3. Statistical Inference:\n",
    "        The normal distribution is closely associated with various statistical inference methods, such as hypothesis testing and confidence intervals. These methods rely on assumptions\n",
    "        of normality to make valid statistical inferences about population parameters based on sample data.\n",
    "        \n",
    "Real-life examples of variables that can often be modeled using the normal distribution include:\n",
    "    \n",
    "    1. Heights and Weights:\n",
    "        The heights and weights of a large population tend to follow a normal distribution. While individuals may have different heights or weights, when measured on a large scale, they\n",
    "        tend to cluster around the mean and exhibit a bell-shaped distribution.\n",
    "        \n",
    "    2. Test Scores:\n",
    "        In educational settings, test scores are often assumed to follow a normal distribution, especially when the test is well-designed and taken by a large number of students.\n",
    "        This assumption allows for the use of statistical methods to analyze and interpret the scores.\n",
    "        \n",
    "    3. IQ Scores:\n",
    "        IQ (Intelligence Quotient) scores are designed to follow a normal distribution, with the mean set to 100 and a standard deviation of 15. This distribution allows for a\n",
    "        standardized comparison of intelligence levels among individuals.\n",
    "        \n",
    "    4. Errors and Residuals:\n",
    "        In various scientific and engineering applications, measurement errors, residuals from regression models, and prediction errors are often assumed to be normally distributed.\n",
    "        This assumption enables the use of statistical techniques to estimate parameters and assess uncertainty.\n",
    "        \n",
    "    5. Financial Data:\n",
    "        In finance and investment, stock returns and other financial variables are often assumed to be normally distributed or approximately so. This assumption forms the basis for many\n",
    "        financial models and risk analysis techniques.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e395434-4707-40f1-8e89-14ac6de0db0c",
   "metadata": {},
   "source": [
    "### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b45008-7a22-4440-87fa-8dae8b6ea4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success and failure. It is named after the Swiss \n",
    "mathematician Jacob Bernoulli. The distribution is characterized by a single parameter, p, which represents the probability of success.\n",
    "\n",
    "Mathematically, the Bernoulli distribution is defined as follows:\n",
    "    \n",
    "    P(X = 1) = p (probability of success)\n",
    "    P(X = 0) = 1 - p (probability of failure)\n",
    "\n",
    "where X is the random variable representing the outcome of the experiment.\n",
    "\n",
    "Example of Bernoulli Distribution:\n",
    "    Consider a coin flip experiment, where we are interested in the outcome of getting a heads (success). The Bernoulli distribution can be used to model this situation, where p\n",
    "    represents the probability of getting heads.\n",
    "\n",
    "If we assume that the probability of getting heads is 0.5, then the Bernoulli distribution can be expressed as:\n",
    "    \n",
    "    P(X = 1) = 0.5 (probability of heads)\n",
    "    P(X = 0) = 1 - 0.5 = 0.5 (probability of tails)\n",
    "\n",
    "In this example, the random variable X takes on the value 1 for heads (success) and 0 for tails (failure).\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "    \n",
    "    Number of Trials:\n",
    "        The Bernoulli distribution models a single trial or experiment with two possible outcomes. It represents a situation where there is only one opportunity for success or failure.\n",
    "        The binomial distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. It represents a situation where multiple trials \n",
    "        are conducted, each with its own probability of success.\n",
    "        \n",
    "    Parameters:\n",
    "        The Bernoulli distribution has a single parameter, p, which represents the probability of success in a single trial.\n",
    "        The binomial distribution has two parameters: n, the number of trials, and p, the probability of success in each trial.\n",
    "        \n",
    "    Random Variable:\n",
    "        The random variable in the Bernoulli distribution can take only two values: 0 (failure) or 1 (success).\n",
    "        The random variable in the binomial distribution represents the number of successes in the fixed number of trials. It can take values from 0 to n, where n is the number of trials.\n",
    "        \n",
    "    Probability Function:\n",
    "        The probability function for the Bernoulli distribution gives the probability of a single outcome (0 or 1).\n",
    "        The probability function for the binomial distribution gives the probability of obtaining a specific number of successes (k) in the given number of trials (n).\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47243dad-8b4f-46fe-aa5a-e5dcc0fd4291",
   "metadata": {},
   "source": [
    "### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3545022-1d31-4c62-b1ed-2f1902863f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "To calculate the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60,\n",
    "we need to use the properties of the normal distribution.\n",
    "\n",
    "The standard formula to calculate probabilities in a normal distribution is by using the Z-score and the cumulative distribution function (CDF).\n",
    "The Z-score represents the number of standard deviations an observation is away from the mean.\n",
    "\n",
    "To find the Z-score for the value 60, we can use the formula:\n",
    "    \n",
    "    Z = (X - μ) / σ\n",
    "    \n",
    "    where X is the value (60), μ is the mean (50), and σ is the standard deviation (10).\n",
    "    \n",
    "    Substituting the values:\n",
    "        \n",
    "        Z = (60 - 50) / 10\n",
    "        Z = 1\n",
    "        \n",
    "        Now, we need to find the probability associated with this Z-score using the standard normal distribution table or calculator.\n",
    "        The probability we are interested in is the area under the curve to the right of Z = 1.\n",
    "        \n",
    "        Using a standard normal distribution table or calculator, we can find that the probability associated with Z = 1 is approximately 0.8413.\n",
    "        \n",
    "        Therefore, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.8413 or 84.13%.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7150aaf-a49d-4784-9304-1292bd1f3aef",
   "metadata": {},
   "source": [
    "### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8669385-6104-4481-ba05-db5da184aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "The uniform distribution is a probability distribution where all values within a specified range are equally likely to occur. It is often represented by a rectangular-shaped probability\n",
    "density function, with a constant probability density over the interval.\n",
    "\n",
    "Mathematically, for a continuous uniform distribution on the interval [a, b], the probability density function (PDF) is defined as:\n",
    "    \n",
    "    f(x) = 1 / (b - a), for a ≤ x ≤ b\n",
    "    f(x) = 0, otherwise\n",
    "\n",
    "This means that any value within the interval [a, b] has an equal chance of being observed, and the probability density is constant within that range.\n",
    "\n",
    "Example of Uniform Distribution:\n",
    "    \n",
    "    Consider a fair six-sided die. The random variable X represents the outcome when the die is rolled. The die has equally likely outcomes, with each face numbered from 1 to 6.\n",
    "    \n",
    "    In this case, the uniform distribution can be used to model the probability of rolling each number. Since each outcome has an equal probability of occurring, the probability \n",
    "    density function (PDF) is as follows:\n",
    "        \n",
    "        f(x) = 1/6, for x = 1, 2, 3, 4, 5, 6\n",
    "        f(x) = 0, otherwise\n",
    "\n",
    "In this example, the probability of rolling any specific number (1, 2, 3, 4, 5, or 6) is equal to 1/6, which is the constant probability density over the interval [1, 6].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf4868-70cb-4fea-a867-20a365c3da2a",
   "metadata": {},
   "source": [
    "### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1c9c3-c26a-4455-bf78-204c5d96021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "The z-score, also known as the standard score, is a measure that indicates how many standard deviations an observation or data point is away from the mean of a distribution.\n",
    "It allows for the standardization and comparison of values across different distributions.\n",
    "\n",
    "Mathematically, the z-score of a data point X, given a distribution with mean μ and standard deviation σ, is calculated using the formula:\n",
    "    \n",
    "    z = (X - μ) / σ\n",
    "\n",
    "The z-score tells us how many standard deviations a data point is above or below the mean. A positive z-score indicates that the data point is above the mean, while a negative z-score \n",
    "indicates that it is below the mean. A z-score of 0 means the data point is at the mean.\n",
    "\n",
    "Importance of the z-score:\n",
    "    \n",
    "    1. Standardization and Comparison:\n",
    "        The z-score allows for the standardization of data across different distributions. It transforms the original data into a standard normal distribution with a mean of 0 and a \n",
    "        standard deviation of 1. This standardization enables meaningful comparisons and analysis of data points from different distributions.\n",
    "        \n",
    "    2. Relative Position:\n",
    "        The z-score provides information about the relative position of a data point within a distribution. By comparing the z-scores of different data points, we can determine which\n",
    "        observations are relatively higher or lower than others.\n",
    "        \n",
    "    3. Probability Calculation:\n",
    "        The z-score is used to calculate probabilities associated with specific values in a normal distribution. By converting values to z-scores, we can use the standard normal\n",
    "        distribution table or calculator to determine the probability of observing a value or range of values.\n",
    "        \n",
    "    4. Outlier Detection:\n",
    "        Z-scores can be used to identify outliers in a dataset. Data points with z-scores that are significantly larger or smaller than the mean suggest unusual or extreme values.\n",
    "        \n",
    "    5. Hypothesis Testing:\n",
    "        The z-score is a crucial component in hypothesis testing. It helps determine whether an observed difference between a sample and a population is statistically significant. \n",
    "        By comparing the z-score to a critical value, we can make decisions regarding the acceptance or rejection of a hypothesis.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1b8ec-9bcf-4567-81c2-11b93d044ff7",
   "metadata": {},
   "source": [
    "### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049694d3-3f10-44de-878d-c3799d40a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sum or average of a large number of independent and identically distributed \n",
    "random variables. It states that regardless of the shape of the original population distribution, as the sample size increases, the distribution of the sample mean approaches a normal \n",
    "distribution.\n",
    "\n",
    "Key points about the Central Limit Theorem:\n",
    "    \n",
    "    1. Large Sample Size:\n",
    "        The Central Limit Theorem holds when the sample size is sufficiently large. Although there is no fixed threshold for what constitutes a \"large\" sample size, a common rule of\n",
    "        thumb is that the sample size should be greater than 30.\n",
    "    \n",
    "    2. Independence and Identical Distribution: \n",
    "        The random variables in the sample must be independent of each other and have the same probability distribution. This assumption ensures that the observations are not influenced \n",
    "        by each other and that the properties of the population distribution are consistent across all observations.\n",
    "        \n",
    "    3. Convergence to Normal Distribution: \n",
    "        The Central Limit Theorem states that as the sample size increases, the distribution of the sample mean approaches a normal distribution, regardless of the shape of the \n",
    "        population distribution. This is true even if the original population distribution is not normally distributed.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "    \n",
    "    1. Normality Assumption:\n",
    "        The Central Limit Theorem allows us to assume a normal distribution for the sample mean, even if the population distribution is unknown or not normally distributed.\n",
    "        This assumption is essential for many statistical techniques and hypothesis testing procedures that rely on normality.\n",
    "        \n",
    "    2. Sampling Variability:\n",
    "        The Central Limit Theorem explains the behavior of the distribution of sample means. It shows that the sampling distribution of the mean becomes increasingly concentrated\n",
    "        around the population mean as the sample size increases. This helps in understanding the variability in sample statistics and making inferences about population parameters.\n",
    "        \n",
    "    3. Hypothesis Testing and Confidence Intervals: \n",
    "        The Central Limit Theorem is crucial for hypothesis testing and constructing confidence intervals. It allows us to use the properties of the normal distribution to make\n",
    "        statistical inferences about population parameters based on sample data. Hypothesis tests and confidence intervals rely on assumptions of normality, which are satisfied \n",
    "        or approximated by the Central Limit Theorem.\n",
    "        \n",
    "    4. Practical Application:\n",
    "        The Central Limit Theorem is widely applied in various fields, such as social sciences, economics, engineering, and natural sciences. It provides a theoretical foundation \n",
    "        for statistical analysis, allowing researchers to make valid inferences from sample data, even when the population distribution is not known or is non-normal.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf2074-aaee-4f37-88f6-7b4ce86f1349",
   "metadata": {},
   "source": [
    "### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fc83a-0db6-43b0-ad1c-aa01b341442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer.\n",
    "The Central Limit Theorem (CLT) relies on certain assumptions to hold true. These assumptions are:\n",
    "    \n",
    "    1. Independent and Identically Distributed (IID) Random Variables:\n",
    "        The random variables in the sample must be independent of each other, meaning that the value of one variable does not depend on the value of another. Additionally, they should\n",
    "        be identically distributed, meaning they have the same probability distribution.\n",
    "        \n",
    "    2. Finite Variance:\n",
    "        The random variables should have a finite variance. This assumption ensures that the spread or variability of the population distribution is not too large.\n",
    "        \n",
    "    3. Finite Sample Size:\n",
    "        The CLT assumes that the sample size is finite. While there is no strict threshold for what constitutes a \"large\" sample size, a common guideline is that the sample size should\n",
    "        be greater than 30. However, for distributions that are heavily skewed or have heavy tails, a larger sample size may be required for the CLT to hold.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34b948-9eb1-4dfe-8ece-79cfa919568d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
